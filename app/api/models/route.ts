import { NextResponse } from 'next/server'
import fs from 'fs'
import path from 'path'

/**
 * üéØ MODELS API v2.0 - Liste tous les mod√®les
 * GET /api/models - Retourne tous les mod√®les avec m√©tadonn√©es enrichies
 */

interface ModelData {
  name: string
  family: string
  size: string
  type?: string
  displayName?: string
  lastUsed?: string
  status: 'ready' | 'loading' | 'error'
  description?: string
  capabilities?: string[]
  specialties?: string[]
  customMetadata?: Record<string, any>
}

/**
 * üìã GET - Liste tous les mod√®les disponibles
 */
export async function GET() {
  console.log('üéØ [MODELS-API] Requ√™te GET - Liste tous les mod√®les')
  
  try {
    // R√©cup√©ration des mod√®les depuis le service Ollama centralis√©
    const baseUrl = process.env.NODE_ENV === 'production' && process.env.VERCEL_URL 
      ? `https://${process.env.VERCEL_URL}` 
      : 'http://localhost:3000'
    
    const ollamaResponse = await fetch(`${baseUrl}/api/ollama`, {
      method: 'GET',
      headers: { 'Content-Type': 'application/json' }
    })

    if (!ollamaResponse.ok) {
      throw new Error(`Erreur Ollama: ${ollamaResponse.status}`)
    }

    const ollamaData = await ollamaResponse.json()
    
    if (!ollamaData.healthy || !ollamaData.models) {
      throw new Error('Service Ollama indisponible ou aucun mod√®le')
    }

    // Chargement de la configuration des mod√®les
    let modelConfigs: Record<string, any> = {}
    try {
      const configPath = path.join(process.cwd(), 'data', 'models-config.json')
      const configFile = fs.readFileSync(configPath, 'utf8')
      const configData = JSON.parse(configFile)
      modelConfigs = configData.models || {}
    } catch (configError: any) {
      console.warn(`‚ö†Ô∏è [MODELS-API] Impossible de charger la configuration:`, configError?.message || 'Erreur inconnue')
    }

    // Enrichissement des mod√®les avec m√©tadonn√©es
    const enrichedModels: ModelData[] = ollamaData.models.map((model: any) => {
      // Extraction du nom du mod√®le (gestion des formats string ou objet)
      const modelName = typeof model === 'string' ? model : model.name || model.model
      
      if (typeof modelName !== 'string') {
        console.warn(`‚ö†Ô∏è [MODELS-API] Format de mod√®le inattendu:`, model)
        return null
      }

      // R√©cup√©ration de la configuration sp√©cifique du mod√®le
      const modelConfig = modelConfigs[modelName] || {}
      
      // Extraction de la famille depuis le nom (premier mot avant ":")
      const familyMatch = modelName.split(':')[0]
      const family = familyMatch.includes('/') ? familyMatch.split('/')[1] : familyMatch

      // Extraction de la taille du mod√®le depuis le nom OU la config
      const sizeFromName = modelName.match(/:(\d+[bB]|\d+\.\d+[bB]|\d+m)/)
      const size = sizeFromName ? sizeFromName[1].toUpperCase() : (modelConfig.parameters || 'Unknown')

      return {
        name: modelName,
        family,
        size,
        type: modelConfig.type || 'general', // Ajout du type !
        displayName: modelConfig.displayName || modelName,
        status: 'ready' as const,
        lastUsed: new Date().toISOString(),
        description: modelConfig.description || `Mod√®le ${family} de taille ${size}`,
        capabilities: ['text-generation', 'conversation'],
        specialties: modelConfig.specialties || [],
        customMetadata: {}
      }
    }).filter(Boolean) // Supprime les entr√©es null

    console.log(`‚úÖ [MODELS-API] ${enrichedModels.length} mod√®les enrichis retourn√©s`)

    return NextResponse.json({
      success: true,
      models: enrichedModels,
      count: enrichedModels.length,
      timestamp: new Date().toISOString()
    })

  } catch (error) {
    console.error('‚ùå [MODELS-API] Erreur:', error)
    
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'Erreur inconnue',
      models: [],
      count: 0
    }, { status: 500 })
  }
}
